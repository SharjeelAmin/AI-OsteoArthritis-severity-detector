# -*- coding: utf-8 -*-
"""Random Forest.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1U8gV9OSMJHbXIbOBhAL1yLpKZGsKz26W

# Data Preproccesing
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
import warnings
warnings.filterwarnings('ignore')
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.model_selection import train_test_split
import seaborn as sns
import matplotlib.pyplot as plt
import xgboost as xg

data = pd.read_csv('/content/multilabel_missing-filled.csv')
data.head()



'''
 print(data["osteophytes"])
 for x in data["osteophytes"]:
  if data["osteophytes"][x] == "def":
    data["osteophytes"][x] = 2
  elif data["osteophytes"][x] == "poss":
    data["osteophytes"][x] = 1
  elif data["osteophytes"][x] == "none":
    data["osteophytes"][x] = 0
  else:
    data["osteophytes"][x] = data["osteophytes"][x]
'''

data["osteophytes"].replace(to_replace = "def", value = 0, inplace = True)
data["osteophytes"].replace(to_replace = "poss", value = 1, inplace = True)
data["osteophytes"].replace(to_replace = "none", value = 2, inplace = True)
data["osteophytes"]

data["jsn"].replace(to_replace = "def", value = 3, inplace = True)
data["jsn"].replace(to_replace = "severe", value = 2, inplace = True)
data["jsn"].replace(to_replace = "mild/mod", value = 1, inplace = True)
data["jsn"].replace(to_replace = "none", value = 0, inplace = True)
data["jsn"]

data

#data.corr(["kl_grade", "osteophytes"])
data.drop("id", axis = 1, inplace = True)
data.drop("side", axis = 1, inplace = True)
data.drop("subset", axis = 1, inplace = True)
data.drop("filename", axis = 1, inplace = True)
data.drop("actual_path", axis = 1, inplace = True)
data.corr(method='pearson')

data2 = pd.read_csv('/content/clinical_info(in).csv')
data2.head()

#data2.drop("ID", axis = 1, inplace = True)
#data2.drop(["SIDE","FILENAME"], axis = 1, inplace = True)
data2.head()

data2["FREQUENT PAIN"].nunique()

data2["FREQUENT PAIN"].replace(to_replace = "5: Freq pain both knees", value = 5, inplace = True)
data2["FREQUENT PAIN"].replace(to_replace = "4: Freq pain 1 knee, infreq pain other knee", value = 4, inplace = True)
data2["FREQUENT PAIN"].replace(to_replace = "3: Freq pain 1 knee, no pain other knee", value = 3, inplace = True)
data2["FREQUENT PAIN"].replace(to_replace = "2: Infreq pain both knees", value = 2, inplace = True)
data2["FREQUENT PAIN"].replace(to_replace = "1: Infreq pain 1 knee, no pain other knee", value = 1, inplace = True)
data2["FREQUENT PAIN"].replace(to_replace = "0: No pain either knee", value = 0, inplace = True)
data2["FREQUENT PAIN"].replace(to_replace = "None", value = 0, inplace = True) # In case there are any "None" values
data2["FREQUENT PAIN"].info() # check to see if everything was converted to int
data2["FREQUENT PAIN"]

data2["SURGERY"].nunique()

data2["SURGERY"].replace(to_replace = "1: Yes", value = 1, inplace = True)
data2["SURGERY"].replace(to_replace = "0: No", value = 0, inplace = True)
data2["SURGERY"].info() # check to see if everything was converted to int
data2["SURGERY"]

data2["RISK"]
data2["RISK"].nunique()

data2["RISK"].replace(to_replace = "5: Progression cohort", value = 5, inplace = True)
data2["RISK"].replace(to_replace = "4: High risk", value = 4, inplace = True)
data2["RISK"].replace(to_replace = "3: Medium risk", value = 3, inplace = True)
data2["RISK"].replace(to_replace = "2: Low risk", value = 2, inplace = True)
data2["RISK"].replace(to_replace = "1: Non-progression cohort", value = 1, inplace = True)
data2["RISK"].replace(to_replace = "2: Incidence cohort: Risk factors  only", value = 2, inplace = True) # In case there are any "None" values
data2["RISK"].replace(to_replace = "3: Incidence cohort: Knee sx + risk factors", value = 3, inplace = True)
data2["RISK"].replace(to_replace = "1: Incidence cohort: Knee symptoms only", value = 1, inplace = True)
data2["RISK"].replace(to_replace = "4: Incidence cohort: Protocol exception", value = 4, inplace = True)
data2["RISK"].replace(to_replace = "0: Non-eligible control cohort", value = 0, inplace = True)
data2["RISK"].replace(to_replace = "None", value = 0, inplace = True)

data2["RISK"].info() # check to see if everything was converted to int
data2["RISK"]

data2["SXKOA"].nunique()

data2["SXKOA"].replace(to_replace = "0: Neither", value = 0, inplace = True)
data2["SXKOA"].replace(to_replace = "1: Right knee only", value = 1, inplace = True)
data2["SXKOA"].replace(to_replace = "3: Both knees", value = 3, inplace = True)
data2["SXKOA"].replace(to_replace = "2: Left knee only", value = 2, inplace = True)
# Handle the value '1' based on your understanding of the data
# For example, if '1' represents a third category, you might assign it a value of 3:
# data2["SXKOA"].replace(to_replace = 1, value = 3, inplace = True)

data2["SXKOA"].info()
data2["SXKOA"]

# First digit of each strng
data2['SWELLING'].nunique()
data2['SWELLING'].unique()

data2["SWELLING"].replace(to_replace = "0: Never", value = 0, inplace = True)
data2["SWELLING"].replace(to_replace = "1: Rarely", value = 1, inplace = True)
data2["SWELLING"].replace(to_replace = "2: Sometimes", value = 2, inplace = True)
data2["SWELLING"].replace(to_replace = "3: Often", value = 3, inplace = True)
data2["SWELLING"].replace(to_replace = "4: Always", value = 4, inplace = True)

data2["SWELLING"].head(50)

data2["BENDING FULLY"].replace(to_replace = "0: Always", value = 0, inplace = True)
data2["BENDING FULLY"].replace(to_replace = "1: Often", value = 1, inplace = True)
data2["BENDING FULLY"].replace(to_replace = "2: Sometimes", value = 2, inplace = True)
data2["BENDING FULLY"].replace(to_replace = "3: Rarely", value = 3, inplace = True)
data2["BENDING FULLY"].replace(to_replace = "4: Never", value = 4, inplace = True)
data2["BENDING FULLY"].head(20)

data2['SYMPTOMATIC'].unique()

data2["SYMPTOMATIC"].replace(to_replace = "0: No", value = 0, inplace = True)
data2["SYMPTOMATIC"].replace(to_replace = "1: Yes", value = 1, inplace = True)

data2["SYMPTOMATIC"]

data2["CREPITUS"].unique()

data2["CREPITUS"].replace(to_replace = "0: No", value = 0, inplace = True)
data2["CREPITUS"].replace(to_replace = "1: Yes", value = 1, inplace = True)
data2["CREPITUS"].head(20)

print(data)
print(data2)
data = pd.concat([data, data2], axis=1, join='inner')
data

data.info()

data.drop(["SIDE","FILENAME"], axis = 1, inplace = True)

data.info()

"""# Checking Data Corr"""

data.dropna(inplace=True)

#make a heatmap for correlation of kl_grade
sns.heatmap(data.corr().iloc[:,:1], annot=True, cmap='coolwarm')
data.corr().iloc[:,:1]

"""#test train split"""

#X = data[["osteophytes","sctm","scfm","ostm","osfm","osfl","ostl"]]
X = X = data.drop("kl_grade", axis=1)
y = data["kl_grade"]
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

X_train = pd.DataFrame(X_train)
X_test = pd.DataFrame(X_test)

from colorsys import yiq_to_rgb
xgb_r = xg.XGBRegressor(random_state = 42,n_jobs=-1, tree_method='gpu_hist')

from sklearn.model_selection import RandomizedSearchCV
from scipy.stats import uniform, randint

rf_regressor = RandomForestRegressor(n_estimators=2000,n_jobs = -1,max_features='log2',bootstrap = True,min_samples_split = 2)
rf_regressor.fit(X_train, y_train)

y_pred = rf_regressor.predict(X_test)
MSE = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)
print("Mean Squared Error:", MSE)
print("R-squared:", r2)



